\section{Visualization} % (fold)
\label{sub:visualization}

The greatest challenge of our work was the creation of the visualization part for its requirements. We will now explain this piece of Eagle Eye, its architecture, visualization techniques, sorting and filtering capabilities.

\subsection{Overview}
We wanted to make the visualization simple and easy to use, while keeping it flexible enough to allow for an enjoyable experience.

After the backend has finished the all the processing that is needed, the visualization can be opened and all images that were added to the backend's processing list will appear. After loading the metadata, the user is presented with a set of options on the top toolbar, which is the only \ac{UI} needed to use the system. \todo{Add picture}


According to \todo{insert the reference of the dude who claimed that a 32x32px image was the minimum for recognition}, an image with 32 pixels per side is the minimum size that allows a user to recognize an image.

\red{Unsure about how well this fits hereâ€¦} Upon loading Eagle Eye's visualization system, thousands of images might be displayed and this 32 pixel might not be met and, therefore, it might be difficult for the user to recognize what is on display from a single image, but since a lot of them are being displayed, the user might be capable of making sense of the groups by their main colors.

\subsubsection{The Canvas}

The canvas is the most relevant part of the visualization as it dynamically displays all the images previously selected by the user, at the same time. This may make the images barely recognizable and, therefore, the user has the possibility of manipulating the canvas to see and enjoy the images.
This means that the user can, at any time, use the mouse to drag the canvas around or, by clicking or scrolling, zoom in and out of the canvas. Zooming goes from the default view of thousands of images at the same time, until the full screen view of one of them, and everything in between in a smooth way.

\subsubsection{The toolbar}

The user can then use the functions on the toolbar to filter and sort differently. The toolbar is divided in three sections: Navigation, Display and Filtering.

The navigation section contains some basic functions that work similarly to the current web browsers. There are buttons for back and forward between display states and a save button for bookmarking the current display state, allowing the user to easily get back to it later.

The middle section contains two options to change the image display:  the sorting options and the display overlays button. The former presents the available sorting options for the current collection, based on the available metadata and on the best ways to display them. One of the options is selected at all times and the content is presented accordingly. Changing the selected option causes the images in display to move around to the new position and form a different sort order. This sorting and disposition options will be explained in a later section.
The other button in the display section of the toolbar enables or disables a layer of information on top of the images. This layer distinguishes the groups of images in display by painting them with a different colors and presents a name for them, depending on the selection sort option. Grouping will also be explained bellow. 

The third and final section of the toolbar is the filter section. It contains controls to filter images by using simple text and to visually select images on the canvas. This options will also be explained bellow.

\subsection{Disposition of Images on Canvas}

The different ways to dispose the images on the canvas was a matter that required some exploration of possibilities \todo{insert references}. We chose a few options to allow some flexibility for the user, while trying to keep the interface simple.

We are now going to explain the image sorting into groups and the different ways the user can arrange those groups on the canvas.

\subsubsection{Sorting images into groups}

As we've seen, the backend outputs metadata for each image. This metadata is loaded into the visualization application of Eagle Eye and is indexed by their type.

For instance, each image has an associated creation timestamp which will be aggregated by days, generating an image group for each day.

Similarly, the mean color associated with each image is indexed and groups are generated by dividing the hue spectrum in bins \todo{specify which and add the spectrum image}.

Another option is the grouping by device name, which usually allows to distinguish between who took the pictures if, for instance, different people have different cameras on the same event.

The last option currently available to the user is grouping by path which groups together the images that were already grouped by the user, on the file system. This allows for the display of an organization that is recognizable to the user, which can make a good starting point.

On the canvas, group boundaries are identifiable by discrete gray borders and, when the Show Overlays function is active, by color rectangles that also contain the groups' names.


\subsubsection{Sorting images into groups}


%%%%%%%%%%%%%%%%%%%%%%%

\hide{As referred on \ref{sub:design_decisions} we built the visualization with the DeepZoom technology of Microsoft's Silverlight, a platform for developing interactive applications for the web that mimics the development of native applications for Microsoft's Windows operating system.}

\subsection{Functionalities}





%%%%%%%%%%%%%%%%%%%%%%%
It runs inside a browser window which can make a very immersive experience when put in fullscreen, since it has a really small space dedicated for controls, levying the rest for images.


The system loads the DeepZoom files and the 


% subsection visualization (end)
