%% This BibTeX bibliography file in UTF-8 format was created using Papers.
%% http://mekentosj.com/papers/

@article{Chang:1988p891,
author = {SF Chang and C Yan and D Dimitroff}, 
journal = {IEEE Transactions on {\ldots}},
title = {An intelligent image database system},
abstract = {An intelligent image database search system is a system capable of searching the digital image databases for user-defined objects. User's information is in the form of acceptance or rejection of retrieved images. This information is used as a collection of positive and negative training examples for a class-specific classification network by identifying clusters in the data. Each network consists of a set of Radial Basis Function neural network with a non-linear perceptron output layer. Relevance feedback is employed to iteratively refine queries. The user can review and adjust the behavior of the network. Color and texture feature vectors represent images for search and retrieval purposes. This project concentrates on examining the effectiveness of the feature set being used and on the RBF training process capability. The ultimate goal is to make more use of user's information and to make a system more operative.},
year = {1988},
month = {Jan},
date-added = {2010-10-04 12:03:32 +0100},
date-modified = {2010-10-23 21:37:27 +0100},
pmid = {5418286491878944986related:2vC9Z9ueMUsJ},
URL = {http://portal.acm.org/citation.cfm?id=630791.631002},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Chang,%20An%20intelligent%20image%20database%20system.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p891},
read = {Yes},
rating = {0}
}

@article{Combs:1999p1465,
author = {T Combs and B Bederson}, 
journal = {{\ldots} of the fourth ACM conference on {\ldots}},
title = {Does zooming improve image browsing?},
abstract = {The  browsers tested during the experiment include Cerious Software's Thumbs Plus, TriVista Technology's Simple LandScape and Photo GoRound, and our Zoomable  based on Pad++. Keywords Evaluation, controlled experiment,  browsers, retrieval },
year = {1999},
month = {Jan},
date-added = {2010-10-23 19:49:32 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {8923610609086205286related:Zo191JEI13sJ},
URL = {http://portal.acm.org/citation.cfm?id=313238.313286},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Combs,%20Does%20zooming%20improve%20image%20browsing?.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1465},
read = {Yes},
rating = {0}
}

@article{Qiu:2011p1253,
author = {G Qiu and L Ye and X Feng}, 
journal = {{\ldots} Workshop on Content-Based Multimedia Indexing},
title = {Fast image indexing and visual guided browsing},
abstract = {Managing the ever rapidly increasing image data is a very challenging task, which can be roughly divided into user side and computer side issues. Although fundamental problems on the computer side of the challenge, such as image content representation, similarity matching and intelligent retrieval have received extensive research effort, equally important and difficult issues on the user side, such as fast indexing, interactive browsing and system usability have not yet been seriously studied. In this paper, we present a framework that integrates fast image indexing and user friendly interface design for easy and intuitive image database browsing. We use natural scene statistics to divide the database into easily describable visual themes, which in turn render extremely efficient indexing, and intuitive and visually meaningful user interface design. We present computer simulation results to demonstrate the effectiveness of the proposed method.},
date-added = {2010-10-13 13:57:46 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {5918124876954952617related:qWNNUzhnIVIJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.60.7812&rep=rep1&type=pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Qiu,%20Fast%20image%20indexing%20and%20visual%20guided%20browsing.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1253},
read = {Yes},
rating = {0}
}

@article{Tan:2001p850,
author = {KL Tan and BC Ooi and CY Yee}, 
journal = {Multimedia Tools and Applications},
title = {An evaluation of color-spatial retrieval techniques for large image databases},
abstract = {In a color-spatial retrieval technique, the color information is integrated with the knowledge of the colors'' spatial distribution to facilitate content-based image retrieval. Several techniques have been proposed in the literature, but these works have been developed independently without much comparison. In this paper, we present an experimental evaluation of three color-spatial retrieval techniques---the signature-based technique, the partition-based algorithm and the cluster-based method. We implemented these techniques and compare them on their retrieval effectiveness and retrieval efficiency. The experimental study is performed on an image database consisting of 12,000 images. With the proliferation of image retrieval mechanisms and the lack of extensive performance study, the experimental results can serve as guidelines in selecting a suitable technique and designing a new technique.
content- based retrievals - color-spatial information - image database - retrieval effectiveness - retrieval efficiency
},
annote = {This paper presents an evaluation of three color-spatial image retrieval techniques.

The signature-based technique creates a signature for each image, based on the most frequent colors, according to a threshold, of each subdivision, or bin, of that image. The comparison between images is made by comparing the main colors present on each bin. It is possible to assign more weight to specific bins according to the user's interest.

The partition-based approach is also based on bins, each having it's own color histogram. The similarity between images is given by the distance of the histograms of the corresponding bins.

The cluster-based method bases on the fact that humans focus on large patches (clusters) of the same color and, therefore, two images will appear similar if both have similar colored clusters on at roughly the same location. This method extracts the larger clusters and their color from each image. The similarity is calculated by the amount of overlap between clusters.

This techniques were tested with a collection of 12,000 images and, besides the color information, the brightness was also analyzed for increased performance. The authors conclude the signature method was generally better on both effectiveness and efficiency.
},
year = {2001},
month = {Jan},
keywords = {Na tese, Resumido}, 
date-added = {2010-10-03 18:19:57 +0100},
date-modified = {2010-10-24 01:12:02 +0100},
pmid = {9308602746181750172&as_sdt=2005&sciodt=2000&hl=en&num=30related:nI1j6eDMLoEJ:scholar.google.com/&hl=en&num=30&as_sdt=2000},
URL = {http://www.springerlink.com/index/H06003Q45658G470.pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Tan,%20An%20evaluation%20of%20color-spatial%20retrieval%20techniques%20for%20large%20image%20databases.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p850},
read = {Yes},
rating = {2}
}

@article{Rodden:2003p2736,
author = {Kerry Rodden and Kenneth R Wood}, 
journal = {Proceedings of the SIGCHI conference on {\ldots}},
title = {How do people manage their digital photographs?},
abstract = {In this paper we present and discuss the findings of a study that investigated how people manage their collections of digital photographs. The six-month, 13-participant study included interviews, questionnaires, and analysis of usage statistics gathered from an instrumented digital photograph management tool called Shoebox. Alongside simple browsing features such as folders, thumbnails and timelines, Shoebox has some advanced multimedia features: content- based image retrieval and speech recognition applied to voice annotations. Our results suggest that participants found their digital photos much easier to manage than their non-digital ones, but that this advantage was almost entirely due to the simple browsing features. The advanced features were not used very often and their perceived utility was low. These results should help to inform the design of improved tools for managing personal digital photographs.},
year = {2003},
month = {Jan},
date-added = {2010-11-08 16:58:24 +0000},
date-modified = {2010-11-10 16:56:52 +0000},
pmid = {5438119353140343993related:uXQbQr0UeEsJ},
URL = {http://portal.acm.org/citation.cfm?id=642611.642682&type=series},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Rodden,%20How%20do%20people%20manage%20their%20digital%20photographs?.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2736},
rating = {0}
}

@article{Anonymous:2011p3474,
title = {CVGPU2010.pdf},
date-added = {2010-12-10 15:00:13 +0000},
date-modified = {2010-12-10 15:00:13 +0000},
URL = {http://www.cs.unc.edu/~rraguram/papers/CVGPU2010.pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/CVGPU2010.pdf.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3474},
rating = {0}
}

@article{Heesch:2008p1094,
author = {Daniel Heesch}, 
journal = {Multimedia Tools and Applications},
title = {A survey of browsing models for content based image retrieval},
abstract = {The problem of content based image retrieval (CBIR) has traditionally been investigated within a framework that emphasises the explicit formulation of a query: users initiate an automated search for relevant images by submitting an image or draw a sketch that exemplifies their information need. Often, relevance feedback is incorporated as a post-retrieval step for optimising the way evidence from different visual features is combined. While this sustained methodological focus has helped CBIR to mature, it has also brought out its limitations more clearly: There is often little support for exploratory search and scaling to very large collections is problematic. Moreover, the assumption that users are always able to formulate an appropriate query is questionable. An effective, albeit much less studied, method of accessing image collections based on visual content is that of browsing. The aim of this survey paper is to provide a structured overview of the different models that have been explored over the last one to two decades, to highlight the particular challenges of the browsing approach and to focus attention on a few interesting issues that warrant more intense research.},
annote = {This work is a survey for around thirty different browsing and image retrieval models.

It explains various concepts of image browsing and organization methodologies and reflects on what needs to be done in the area exposing some of its problems.

Expresses the need of the users to have more flexibility on their search queries and a precomputed structure of images calculated by a single distance metric don't allow the users to impose their own perception of similarity.

Although distance calculations can be very costly, it's an option if it only needs to be made once and can be updated when new images are added without recalculating the entire collection.

Avoid rigid structures or slow queries. Hybrid structure with various precomputed groups but flexible to be relevant and responsive is an idea.

Concludes with the thought of interactive browsing frameworks are better suited for photo explorations and image retrieval than systems that require explicit user queries.
},
year = {2008},
month = {Jan},
date-added = {2010-10-04 12:07:08 +0100},
date-modified = {2010-11-10 16:56:15 +0000},
pmid = {4642436428103693197related:jTN0rVU_bUAJ},
URL = {http://www.springerlink.com/index/M8X1567R331G2405.pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Heesch,%20A%20survey%20of%20browsing%20models%20for%20content%20based%20image%20retrieval.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1094},
read = {Yes},
rating = {4}
}

@inproceedings{Bederson:2001:PZI:502348.502359,
author = {Benjamin B Bederson}, 
journal = {Proceedings of the 14th annual ACM symposium on User interface software and technology},
title = {PhotoMesa: a zoomable image browser using quantum treemaps and bubblemaps},
affiliation = {New York, NY, USA},
pages = {71--80},
year = {2001},
keywords = {Jazz, Animation, Graphics, Zoomable User Interfaces (ZUIs), Image Browsers, Treemaps}, 
date-added = {2010-11-15 10:28:10 +0000},
date-modified = {2010-11-15 10:32:05 +0000},
doi = {http://doi.acm.org/10.1145/502348.502359},
URL = {http://doi.acm.org/10.1145/502348.502359},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Bederson,%20PhotoMesa%20a%20zoomable%20image%20browser%20using%20quantum%20treemaps%20and%20bubblemaps-1.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3150},
read = {Yes},
rating = {0}
}

@article{Datta:2008p1604,
author = {R Datta and D Joshi and J Li and J Wang}, 
journal = {ACM Computing Surveys (CSUR)},
title = {Image retrieval: Ideas, influences, and trends of the new age},
abstract = {We have witnessed great interest and a wealth of promise in content-based image retrieval as an emerging technology. While the last decade laid foundation to such promise, it also paved the way for a large number of new techniques and systems, got many new people },
year = {2008},
month = {Jan},
date-added = {2010-10-23 19:57:44 +0100},
date-modified = {2010-10-23 21:35:41 +0100},
pmid = {18171205470662849289related:CXN-sxkXLfwJ},
URL = {http://portal.acm.org/citation.cfm?id=1348246.1348248},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Datta,%20Image%20retrieval%20Ideas%20influences%20and%20trends%20of%20the%20new%20age.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1604},
rating = {0}
}

@article{Fonseca:2003p3475,
author = {M.J Fonseca and J.A Jorge}, 
journal = {Proc. of the 8th Int'l Conf. on Database Systems for Advanced Applications. Kyoto: IEEE Computer Society},
title = {NB-Tree: An indexing structure for content-based retrieval in large databases},
pages = {267--274},
year = {2003},
date-added = {2011-03-25 18:43:28 +0000},
date-modified = {2011-03-25 18:46:27 +0000},
pmid = {9790863697033196599related:N3Tugagi4IcJ},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Fonseca,%20NB-Tree%20An%20indexing%20structure%20for%20content-based%20retrieval%20in%20large%20databases.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3475},
read = {Yes},
rating = {0}
}

@article{Chen:1998p2344,
author = {Jau-Yuen Chen and Charles A Bouman and John C Dalton}, 
journal = {Human Vision and Electronic Imaging III},
title = {Similarity pyramids for browsing and organization of large image databases},
abstract = {The advent of large image databases (>10,000) has created a need for tools which can search and organize images automatically by their content. This paper presents a method for designing a hierarchical browsing environment which we call a similarity pyramid. The similarity pyramid groups similar images together while allowing users to view the database at varying levels of resolution. We show that the similarity pyramid is best constructed using agglomerative (bottom-up) clustering methods, and present a fast-sparse clustering method which dramatically reduces both memory and computation over conventional methods. We then present a objective measure of pyramid organization called dispersion, and we use it to show that our fast-sparse cluster method produces better similarity pyramids than top down approaches.},
pages = {563--575},
volume = {3299},
year = {1998},
month = {Jan},
date-added = {2010-10-30 12:07:45 +0100},
date-modified = {2010-11-10 16:56:05 +0000},
pmid = {13066224611799535815related:xxDHfQ6OVLUJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.3850&rep=rep1&type=pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Chen,%20Similarity%20pyramids%20for%20browsing%20and%20organization%20of%20large%20image%20databases.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2344},
read = {Yes},
rating = {2}
}

@article{Jain:1996p853,
author = {AK Jain and A Vailaya}, 
journal = {Pattern Recognition},
title = {Image retrieval using color and shape},
abstract = {This paper deals with efficient retrieval of images from large databases based on the color and shape content in images. With the increasing popularity of the use of large-volume image databases in various applications, it becomes imperative to build an automatic and efficient retrieval system to browse through the entire database. Techniques using textual attributes for annotations are limited in their applications. Our approach relies on image features that exploit visual cues such as color and shape. Unlike previous approaches which concentrate on extracting a single concise feature, our technique combines features that represent both the color and shape in images. Experimental results on a database of 400 trademark images show that an integrated color- and shape-based feature representation results in 99% of the images being retrieved within the top two positions. Additional results demonstrate that a combination of clustering and a branch and bound-based matching scheme aids in improving the speed of the retrievals.
},
year = {1996},
month = {Jan},
date-added = {2010-10-03 18:19:57 +0100},
date-modified = {2010-10-23 21:37:57 +0100},
pmid = {4310351151115606045&as_sdt=2005&sciodt=2000&hl=en&num=30related:HRhx44hx0TsJ:scholar.google.com/&hl=en&num=30&as_sdt=2000},
URL = {http://linkinghub.elsevier.com/retrieve/pii/0031320395001603},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Jain,%20Image%20retrieval%20using%20color%20and%20shape.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p853},
read = {Yes},
rating = {0}
}

@article{Azzam:2005p849,
author = {IA Azzam and CHC Leung and JF Horwood}, 
title = {A fuzzy expert system for concept-based image indexing and retrieval},
abstract = {Image indexing and retrieval using a concept-based approach involves extraction, modelling and indexing of image content information. Computer vision offers a variety of techniques for searching images in large collections. We propose a method that enables components of an image to be categorised on the basis of their relative importance in combination with filtered representations. Our method concentrates on matching subparts of images, defined in a variety of ways, in order to find particular objects. These ideas are illustrated with a variety of examples. We focus on Concept- based Image Indexing and Retrieval (CIIR), using a fuzzy expert systems, density measure, supporting factors and other attributes of image components to identify and retrieve images accurately and efficiently.},
year = {2005},
date-added = {2010-09-28 15:08:56 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {8067349178410058913related:ocQrylX79G8J},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Azzam,%20A%20fuzzy%20expert%20system%20for%20concept-based%20image%20indexing%20and%20retrieval.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p849},
rating = {0}
}

@inproceedings{Girgensohn:2010,
author = {Andreas Girgensohn and Frank Shipman and Thea Turner and Lynn Wilcox}, 
journal = {Proceedings of the 10th annual joint conference on Digital libraries},
title = {Flexible access to photo libraries via time place, tags, and visual features},
affiliation = {New York, NY, USA},
pages = {187--196},
year = {2010},
keywords = {similarity criteria, photo retrieval, geographic data, tagged photos, visual similarity, photo libraries}, 
date-added = {2010-11-14 23:20:37 +0000},
date-modified = {2010-11-17 12:03:12 +0000},
doi = {http://doi.acm.org/10.1145/1816123.1816151},
URL = {http://doi.acm.org/10.1145/1816123.1816151},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Girgensohn,%20Flexible%20access%20to%20photo%20libraries%20via%20time%20place%20tags%20and%20visual%20features-1.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3019},
read = {Yes},
rating = {5}
}

@article{Rui:1999p949,
author = {Y Rui and TS Huang and SF Chang}, 
journal = {Journal of visual communication and image {\ldots}},
title = {Image Retrieval: Current Techniques, Promising Directions, and Open Issues* 1},
abstract = { - systems. IEEE Computer (1981). 25. S.-K. Chang and A. Hsu ,  information systems: Where do we go from here?. IEEE Trans. on Knowledge and Data Engineering 4 (1992). 26. S.-K. Chang, CW Yan, DC Dimitroff and T. Arndt , An intelligent   },
year = {1999},
month = {Jan},
date-added = {2010-10-04 12:05:11 +0100},
date-modified = {2010-10-23 21:37:53 +0100},
pmid = {14268029497848731227related:W5YRqDs5AsYJ},
URL = {http://linkinghub.elsevier.com/retrieve/pii/S1047320399904133},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Rui,%20Image%20Retrieval%20Current%20Techniques%20Promising%20Directions%20and%20Open%20Issues*%201.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p949},
read = {Yes},
rating = {0}
}

@article{Fogarty:2008p3240,
author = {J Fogarty and D Tan and Ashish Kapoor and Simon Winder}, 
journal = {Proceeding of the twenty-sixth annual SIGCHI conference on Human factors in computing systems},
title = {CueFlik: interactive concept learning in image search},
abstract = {Web image search is difficult in part because a handful of keywords are generally insufficient for characterizing the visual properties of an image. Popular engines have begun to provide tags based on simple characteristics of images (such as tags for black and white images or images that contain a face), but such approaches are limited by the fact that it is unclear what tags end-users want to be able to use in examining Web image search results. This paper presents CueFlik, a Web image search application that allows end-users to quickly create their own rules for re-ranking images based on their visual characteristics. End-users can then re-rank any future Web image search results according to their rule. In an experiment we present in this paper, end-users quickly create effective rules for such concepts as ``product photos'', ``portraits of people'', and ``clipart''. When asked to conceive of and create their own rules, participants create such rules as ``sports action shot'' with images from queries for ``basketball'' and ``football''. CueFlik represents both a promising new approach to Web image search and an important study in end-user interactive machine learning.},
pages = {29--38},
year = {2008},
month = {Jan},
date-added = {2010-11-16 18:48:21 +0000},
date-modified = {2010-11-16 18:51:11 +0000},
pmid = {1846715879040205372related:PMJDw07aoBkJ},
URL = {http://portal.acm.org/citation.cfm?id=1357054.1357061},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Fogarty,%20CueFlik%20interactive%20concept%20learning%20in%20image%20search.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3240},
rating = {0}
}

@article{Worring:2008p2876,
author = {M Worring}, 
journal = {Journal of Visual Languages {\&} Computing},
title = {Interactive access to large image collections using similarity-based visualization},
abstract = { Permissions {\&} Reprints.   to     - . GP  Corresponding Author Contact Information , a , E-mail The Corresponding Author and .  a , E-mail The Corresponding Author. },
year = {2008},
month = {Jan},
date-added = {2010-11-11 20:14:31 +0000},
date-modified = {2010-11-11 20:14:31 +0000},
pmid = {11130610509351816103related:pwslJ0nfd5oJ},
URL = {http://linkinghub.elsevier.com/retrieve/pii/S1045926X0600053X},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Worring,%20Interactive%20access%20to%20large%20image%20collections%20using%20similarity-based%20visualization.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2876},
read = {Yes},
rating = {0}
}

@inproceedings{Girgensohn:2009:MOP:1502650.1502711,
author = {Andreas Girgensohn and Frank Shipman and Lynn Wilcox and Thea Turner and Matthew Cooper}, 
journal = {Proceedings},
title = {MediaGLOW: organizing photos in a graph-based workspace},
affiliation = {New York, NY, USA},
pages = {419--424},
year = {2009},
keywords = {photo sharing, photo organization, photo retrieval}, 
date-added = {2010-11-19 13:33:55 +0000},
date-modified = {2010-11-19 13:33:56 +0000},
doi = {http://doi.acm.org/10.1145/1502650.1502711},
URL = {http://doi.acm.org/10.1145/1502650.1502711},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Girgensohn,%20MediaGLOW%20organizing%20photos%20in%20a%20graph-based%20workspace.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3297},
read = {Yes},
rating = {0}
}

@article{Heesch:2004p2675,
author = {Daniel Heesch and Stefan R{\"u}ger}, 
journal = {Advances in Information Retrieval},
title = {NNk networks for content-based image retrieval},
abstract = {Abstract. This paper describes a novel interaction technique to sup- port content-based image search in large image collections. The idea is to represent each image as a vertex in a directed graph. Given a set of image features, an arc is established between two images if there exists at least one combination of features for which one image is retrieved as the nearest neighbour of the other. Each arc is weighted by the propor- tion of feature combinations for which the nearest neighour relationship holds. By thus integrating the retrieval results over all possible feature combinations, the resulting network helps expose the semantic richness of images and thus provides an elegant solution to the problem of feature weighting in content-based image retrieval. We give details of the method used for network generation and describe the ways a user can interact with the structure. We also provide an analysis of the network's topology and provide quantitative evidence for the usefulness of the technique.},
pages = {253--266},
year = {2004},
month = {Jan},
date-added = {2010-11-03 11:16:56 +0000},
date-modified = {2010-11-10 16:56:15 +0000},
pmid = {13939138376748041433related:2QQVPYDEccEJ},
URL = {http://www.springerlink.com/index/EXDX902H4NTDTFKD.pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Heesch,%20NNk%20networks%20for%20content-based%20image%20retrieval.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2675},
read = {Yes},
rating = {3}
}

@article{Rodden:2001p731,
author = {Kerry Rodden and W Basalaj and D Sinclair and Kenneth R Wood}, 
journal = {Proceedings of the SIGCHI conference on Human factors in computing systems},
title = {Does organisation by similarity assist image browsing?},
abstract = {In current systems for browsing image collections, users are presented with sets of thumbnail images arranged in some default order on the screen. We are investigating whether it benefits users to have sets of thumbnails arranged according to their mutual similarity, so images that are alike are placed together. There are, of course, many possible definitions of ``similarity'': so far we have explored measurements based on low-level visual features, and on the textual captions assigned to the images. Here we describe two experiments, both involving designers as the participants, examining whether similarity-based arrangements of the candidate images are helpful for a picture selection task. Firstly, the two types of similarity-based arrangement were informally compared. Then, an arrangement based on visual similarity was more formally compared with a control of a random arrangement. We believe this work should be of interest to anyone designing a system that involves presenting sets of images to users.},
annote = {Este trabalho tenta perceber se organizar imagens pelas suas semelhan{\c c}as, sejam de descri{\c c}{\~a}o ou de cor {\'e} ben{\'e}fico para os utilizadores.
Foi realizados testes com utilizadores em que tinham que escolher certas imagens num grupo com v{\'a}rias imagens que podia ser visualizado com dois arranjos diferentes.
Quando est{\~a}o organizadas por uma descri{\c c}{\~a}o b{\'a}sica torna-se f{\'a}cil diminuir a procura a um subconjunto de imagens. A utilidade desta organiza{\c c}{\~a}o depende muito do qu{\~a}o boas s{\~a}o as descri{\c c}{\~o}es. Mostrar as descri{\c c}{\~o}es dos grupos de imagens tamb{\'e}m {\'e} relevante para se perceber qual {\'e} a sua liga{\c c}{\~a}o.
Uma organiza{\c c}{\~a}o por semelhan{\c c}a visual permite dividir as imagens por tipo mas tamb{\'e}m faz com que imagens semelhantes se diluam no meio das outras. Quando o utilizador n{\~a}o sabe bem o que pretende, ordenar as imagens aleatoriamente pode ser mais {\'u}til pois as imagens mais relevantes saltam {\`a} vista.
Tamb{\'e}m {\'e} {\'u}til para algumas pessoas ter acesso a diferentes formas de visualiza{\c c}{\~a}o das mesmas imagens, embora isto n{\~a}o tenha sido muito explorado.
},
pages = {197},
year = {2001},
keywords = {Resumido, Na tese}, 
date-added = {2010-08-09 16:51:04 +0100},
date-modified = {2010-11-10 16:56:52 +0000},
pmid = {14164383941542911965related:3Z_pESYAksQJ},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Rodden,%20Does%20organisation%20by%20similarity%20assist%20image%20browsing?.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p731},
read = {Yes},
rating = {4}
}

@article{Campbell:2000p2017,
author = {I Campbell and C van Rijsbergen}, 
journal = {Citeseer},
title = {The ostensive model of developing information-needs},
abstract = { Submitted for the degree of Doctor of Philosophy to the  of  from the Department of Computing Science September  Copyright {\copyright} Iain   Page 2. An   of  - 1 Acknowledgements },
year = {2000},
month = {Jan},
date-added = {2010-10-27 15:59:25 +0100},
date-modified = {2010-10-27 15:59:25 +0100},
pmid = {11242263938841736121related:uXPYAX2LBJwJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.390&rep=rep1&type=pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Campbell,%20The%20ostensive%20model%20of%20developing%20information-needs.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2017},
rating = {0}
}

@article{Naaman:2004p1802,
author = {M Naaman and Y Song and A Paepcke}, 
journal = {Digital Libraries},
title = {Automatic organization for digital photographs with geographic coordinates},
abstract = {We describe PhotoCompas, a system that utilizes the time and location information embedded in digital photographs to automatically organize a personal photo collection. Pho- toCompas produces browseable location and event hierar- chies for the collection. These hierarchies are created using algorithms that interleave time and location to produce an organization that mimics the way people think about their photo collections. In addition, the algorithm annotates the generated hierarchy with geographical names. We tested our approach in case studies of three real-world collections and verified that the results are meaningful and useful for the collection owners.},
annote = {In this paper is described a system that organizes digital photographies accordingly to location and date embedded on the metadata.

The objective was trying to mimmic the the way people think about their collections. Photos are usually bursts separated by some time. Based on this and on the different places, events can be created to agglomerate photos from the same bursts. Location naming is done by calculating the most relevant places, like parks or cities, and then mixing the more precise locations with the more important neighbor cities to create a relevant and identifiable name. This was specially important since this work didn't involve showing any maps but only the location names and events.

The authors showed good results and, nowadays, some common applications use similar features although including maps.
},
year = {2004},
month = {Jan},
keywords = {Na tese, Resumido}, 
date-added = {2010-10-24 11:42:35 +0100},
date-modified = {2010-10-26 12:23:27 +0100},
pmid = {143662330582398944related:4Pf35SBk_gEJ},
URL = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1336098},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Naaman,%20Automatic%20organization%20for%20digital%20photographs%20with%20geographic%20coordinates.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1802},
read = {Yes},
rating = {2}
}

@article{Torralba:2008p527,
author = {Antonio Torralba and Rob Fergus and William T. Freeman}, 
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
title = {80 Million Tiny Images: A Large Data Set for Nonparametric Object and Scene Recognition},
abstract = {With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of non-parametric methods, we explore this world with the aid of a large dataset of 79,302,017 images collected from the Internet. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the dataset are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 non-abstract nouns in English, as listed in the Wordnet lexical database. Hence the image database gives a comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with nearest-neighbor methods to perform object classification over a range of semantic levels minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the dataset, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.},
annote = {Este trabalho mostra v{\'a}rias coisas que se podem fazer com uma enorme base de dados de imagens.

Procurando 75 mil palavras chave em sete motores de busca online e associando a palavra {\`a} imagem obtiveram 8 milh{\~o}es de imagens. Guardaram estas imagens a 32x32 piseis, no que demonstraram ser o tamanho m{\'\i}nimo que permite o reconhecimento visual humano. Este tamanho facilita as opera{\c c}{\~o}es sobre o enorme conjunto de dados.
As keywords fazem parte de uma {\'a}rvore sem{\^a}ntica bem estruturada (Wordnet).
Utilizaram sistemas de correla{\c c}{\~a}o para encontrar imagens semelhantes e duplicadas. Quanto maior o tamanho do conjunto de dados, melhores os conjuntos de imagens semelhantes. Transforma{\c c}{\~o}es da imagem tamb{\'e}m foram utilizadas para melhorar as correspond{\^e}ncias.
{\'E} tamb{\'e}m poss{\'\i}vel fazer reconhecimento de novas imagens procurando pelas keywords mais comuns do conjunto de imagens que {\'e} semelhante {\`a} imagem dada, ou seja, um sistema de voto.
Uma das coisas que fizeram com o sistema de voto foi identificar que fotos continham pessoas e mostraram mais sucesso que uma procura normal num motor de busca. Tamb{\'e}m conseguiram identificar onde, na fotografia, estava a pessoa, por compara{\c c}{\~a}o de subdivis{\~o}es da imagem inicial.
Outra coisa interessante que fizeram foi a coloriza{\c c}{\~a}o autom{\'a}tica de imagens em cinzento, obtendo as cores das imagens semelhantes e aplicando na imagem de entrada.


------------------------------------------

This work shows many of the things that can be done with a huge data base of small images.

Using the lexical database WordNet, 75 thousand words where searched on 7 different online image search engines and accumulated nearly 80 million images. This images were stored at 32x32 pixels, a value found good enough for human recognition of scenes and objects, with the respective keyword associated.

A few interesting uses for this database were found. Image matching was used to identify similar images. Also with image matching was possible to recognize new images by obtaining the most common keywords from the image set similar to first.

Recognizing pictures with people was another usage and showed better results than a common search in a search engine, with the extra of identifying where the person was in the picture.

Another interesting thing the authors managed to do was coloring some grayscale pictures based on similar ones, either by suggesting some common colorization options or by calculating an average of the whole similar set.
},
number = {11},
pages = {1958--1970},
volume = {30},
year = {2008},
date-added = {2010-07-21 11:40:06 +0100},
date-modified = {2010-11-17 17:31:52 +0000},
doi = {http://dx.doi.org/10.1109/TPAMI.2008.128},
URL = {http://portal.acm.org/citation.cfm?id=1444403%23},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Torralba,%2080%20Million%20Tiny%20Images%20A%20Large%20Data%20Set%20for%20Nonparametric%20Object%20and%20Scene%20Recognition.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p527},
read = {Yes},
rating = {3}
}

@article{Bruijn:2000p567,
author = {Oscar Bruijn and Robert Spence}, 
journal = {AVI '00: Proceedings of the working conference on Advanced visual interfaces},
title = {Rapid serial visual presentation: a space-time trade-off in information presentation},
abstract = {Rapid Serial Visual Presentation, or RSVP, is the electronic equivalent of riffling a book in order to assess its content. RSVP allows space to be traded for time and has tremendous potential to support electronic information browsing and search particularly on small displays. However, before this potential can be realised, it is necessary to investigate the parameters involved in the successful application of RSVP in the user interface. The rapid display of images or text is well within the capabilities of current desktop computers and even of current or near future mobile devices. The limiting factor in the application of RSVP, therefore, has to be the limited capability of the user's visual system. Users' reading comprehension with RSVP of text has been studied extensively. The transfer of information with RSVP of images, however, has received relatively little attention. This paper examines some of the problems with applying RSVP for image browsing and search.},
annote = {R{\'a}pida apresenta{\c c}{\~a}o visual em s{\'e}rie (RSVP) {\'e} o equivalente a folhear um livro rapidamente para se ficar com uma ideia do conte{\'u}do.

A r{\'a}pida passagem de imagens ou texto num ecr{\~a} tem potencial para ser uma boa forma de navega{\c c}{\~a}o lienar de informa{\c c}{\~a}o mas {\'e} necess{\'a}rio investigar os parametros para o seu sucesso.

O RSVP troca o espa{\c c}o (v{\'a}rias imagens partilham o espa{\c c}o disponivel) pelo tempo (uma imagem ocupa todo o espa{\c c}o disponivel mas durante apenas numa fra{\c c}{\~a}o do tempo) e {\'e} particularmente {\'u}til em ecr{\~a}s pequenos, onde o espa{\c c}o {\'e} limitado.

{\'E} no entanto de considerar que os utilizadores em geral t{\^e}m problemas com a procura por v{\'a}rias imagens ao mesmo tempo utilizando este m{\'e}todo.

O tempo em que as imagens s{\~a}o mostradas influencia dramaticamente a capacidade do utilizador para se lembrar delas.

Nota: Algumas aplica{\c c}{\~o}es da Apple utilizam esta t{\'e}cnica {\`a} qual chamaram "skim", nomeadamente no iPhoto onde passando com o rato por cima da imagem de capa de um album de fotos s{\~a}o mostradas em vez dessa imagem as outras fotos desse {\'a}lbum, dependendo da posi{\c c}{\~a}o do rato sobre a {\'a}rea da imagem. Isto permite ao utilizador controlar a velocidade com que quer ver as imagens, serve s{\'o} para identificar que imagens est{\~a}o dentro de um {\'a}lbum, podendo fazer skim pelos v{\'a}rios {\'a}lbuns mostrados, identificando facilmente os conjuntos de imagens. Tamb{\'e}m utilizam esta t{\'e}cnica no iTunes, para mostrar {\'a}lbuns de artistas, no iMovie para mostrar o conte{\'u}do de v{\'\i}deos e na galeria de fotos online do MobileMe e para ver os temas nas galerias das aplica{\c c}{\~o}es de produtividade.
N{\~a}o encontrei informa{\c c}{\~a}o em papers sobre esta funcionalidade.},
year = {2000},
month = {May},
keywords = {visualisation, space-time trade-off, image browsing, information navigation, rapid serial visual presentation}, 
date-added = {2010-08-09 16:37:26 +0100},
date-modified = {2010-10-23 21:35:41 +0100},
pmid = {345513.345309},
URL = {http://portal.acm.org/citation.cfm?id=345513.345309},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Bruijn,%20Rapid%20serial%20visual%20presentation%20a%20space-time%20trade-off%20in%20information%20presentation.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p567},
read = {Yes},
rating = {3}
}

@article{Rodden:1999p2740,
author = {Kerry Rodden}, 
journal = {BCS IRSG 21st Ann. Colloq. on Info. Retrieval {\ldots}},
title = {How do people organise their photographs},
abstract = {Increasing use of digital cameras will lead to more people having large personal collections of digital photographs. The study described in this paper set out to gain some insight into how computer-based systems to help people or- ganise these images might be designed. Firstly, taking inspiration from earlier work by others on the management of personal documents, we interviewed people about the ways in which they currently organise their physical photograph collections. Secondly, in an attempt to establish how information retrieval techniques could be of use in this appli- cation area, we also asked the interviewees for their opinions of a number of possible features of a computer-based system for organising and retrieving personal photographs.},
year = {1999},
month = {Jan},
date-added = {2010-11-08 16:58:24 +0000},
date-modified = {2010-11-10 16:56:41 +0000},
pmid = {17823617398356549000related:iJ2DGZc1WvcJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.1787&rep=rep1&type=pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Rodden,%20How%20do%20people%20organise%20their%20photographs.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2740},
rating = {0}
}

@article{Cunningham:6p2782,
author = {Sally Cunningham and Masood Masoodian}, 
title = {Identifying personal photo digital library features},
pages = {401},
year = {6},
month = {Jan},
date-added = {2010-11-08 17:05:27 +0000},
date-modified = {2010-11-08 17:05:27 +0000},
doi = {10.1145/1255175.1255254},
URL = {http://portal.acm.org/citation.cfm?id=1255175.1255254},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Cunningham,%20Identifying%20personal%20photo%20digital%20library%20features.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2782},
read = {Yes},
rating = {0}
}

@article{Porta:2006p416,
author = {Marco Porta}, 
journal = {AVI '06: Proceedings of the working conference on Advanced visual interfaces},
title = {Browsing large collections of images through unconventional visualization techniques},
abstract = {
In this paper we describe some alternative methods intended for rapid and effective browsing of large collections of images. Specifically, we address the user who, not having a clear idea about what to search, needs to explore the entire image database to identify what he or she likes. The purpose of our approaches is to find techniques characterized by good trade-offs between browsing time and quality of the exploration.},
annote = {Este paper descreve v{\'a}rios m{\'e}todos de visualiza{\c c}{\~a}o de grandes conjuntos de imagens para o utilizador que n{\~a}o sabe bem o que procura. O objectivo {\'e} encontrar t{\'e}cnicas/met{\'a}foras que proporcionem uma boa experi{\^e}ncia de visualiza{\c c}{\~a}o em termos de tempo gasto e qualidade.

Foram v{\'a}rias as t{\'e}cnicas usadas, desde a simples grelha de imagens, uma grelha cuja largura e altura das imagens {\'e} vari{\'a}vel e independente (EIB), uma vista em que as imagens aparecem como que disparadas de longe e chegam at{\'e} ao utilizador (Shot), outra vista onde as imagens aparecem muito rapidamente em posi{\c c}{\~o}es aleat{\'o}rias (Spot), e ainda algumas vistas menos comuns como uma vista que simula um cilindro de imagens (Cylinder), e outras menos produtivas (Rotor, Tornado e Tornado of planes).

Os testes basearam-se na efici{\^e}ncia de pesquisas de certas imagens no meio de 1000 fotos pelos utilizadores sendo que a vista Spot foi a mais bem sucedida, seguida pelo Shot, Cylinder e finalmente a vista comum de grelha.

Aparentemente pode-se retirar deste paper que imagens a aparecer rapidamente {\'e} um m{\'e}todo de visualiza{\c c}{\~a}o que facilita as procuras. Outros papers tamb{\'e}m referem que anima{\c c}{\~o}es n{\~a}o s{\~a}o aconselh{\'a}veis e que focar a vis{\~a}o por pouco tempo, nas imagens chega para as reconhecer.},
year = {2006},
month = {May},
keywords = {Resumido, Na tese}, 
date-added = {2010-07-21 10:46:29 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {1133265.1133354},
URL = {http://portal.acm.org/ft_gateway.cfm?id=1133354&type=pdf&coll=Portal&dl=GUIDE&CFID=97746469&CFTOKEN=40297416},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Porta,%20Browsing%20large%20collections%20of%20images%20through%20unconventional%20visualization%20techniques.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p416},
read = {Yes},
rating = {5}
}

@article{10.1109/TABLETOP.2007.14,
author = {Otmar Hilliges and Dominikus Baur and Andreas Butz}, 
journal = {Horizontal Interactive Human-Computer Systems, International Workshop on},
title = {Photohelix: Browsing, Sorting and Sharing Digital Photo Collections},
affiliation = {Los Alamitos, CA, USA},
pages = {87--94},
volume = {0},
year = {2007},
date-added = {2010-11-15 10:35:28 +0000},
date-modified = {2010-11-15 10:35:28 +0000},
doi = {http://doi.ieeecomputersociety.org/10.1109/TABLETOP.2007.14},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Hilliges,%20Photohelix%20Browsing%20Sorting%20and%20Sharing%20Digital%20Photo%20Collections.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3227},
rating = {0}
}

@article{Wojciech:1999p330,
author = {K Wojciech and W Basalaj and D Sinclair{\ldots}}, 
journal = {the IEEE Symposium on {\ldots}},
title = {Evaluating a Visualisation of Image Similarity as a Tool for Image Browsing},
abstract = {A similarity metric based on the low-level content of images can be used to create a visualisation in which visually similar images are displayed close to each other. We are carrying out a series of experiments to evaluate the usefulness of this type of visualisation as an image },
year = {1999},
month = {Jan},
date-added = {2010-12-09 15:36:26 +0000},
date-modified = {2010-12-09 15:36:26 +0000},
URL = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.6798},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Wojciech,%20Evaluating%20a%20Visualisation%20of%20Image%20Similarity%20as%20a%20Tool%20for%20Image%20Browsing.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3473},
rating = {0}
}

@article{Bruls:2000p3517,
author = {Mark Bruls and Kees Huizing and Jarke J. Van Wijk}, 
journal = {Proceedings of the joint Eurographics and IEEE TCVG Symposium on Visualization},
title = {Squarified Treemaps},
abstract = {An extension to the treemap method for the visualization of hierarchicalinformation, such as directory structures and organization structures, is presented.The standard treemap method often gives thin, elongated rectangles. As aresult, rectangles are difficult to compare and to select. A new method is presentedto generate lay-outs in which the rectangles approximate squares. To strenghtenthe visualization of the structure, shaded frames are used around groups of relatednodes.},
affiliation = {Eindhoven University of Technology; Dept . of Mathematics and Computer Science,},
pages = {33--42},
year = {2000},
month = {Apr},
language = {eng},
date-added = {2011-09-21 17:17:34 +0100},
date-modified = {2011-09-21 17:24:00 +0100},
pmid = {326885},
URL = {http://citeseer.ist.psu.edu/326885},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Bruls,%20Squarified%20Treemaps-1.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p3517},
read = {Yes},
rating = {0}
}

@article{Minka:1996p2247,
author = {T Minka and R Picard}, 
journal = {Computer Vision and Pattern Recognition, 1996. Proceedings CVPR '96, 1996 IEEE Computer Society Conference on},
title = {Interactive learning with a ``Society of Models''},
abstract = {Digital library access is driven by features, but the relevance of a feature for a query is not always obvious. This paper describes an approach for integrating a large number of context-dependent features into a semi-automated tool. Instead of requiring universal similarity measures or manual selection of relevant features, the approach provides a learning algorithm for selecting and combining groupings of the data, where groupings can be induced by highly specialized features. The selection process is guided by positive and negative examples from the user. The inherent combinatorics of using multiple features is reduced by a multistage grouping generation, weighting, and collection process. The stages closest to the user are trained fastest and slowly propagate their adaptations back to earlier stages. The weighting stage adapts the collection stage's search space across uses, so that, in later interactions, good groupings are found given few examples from the user},
pages = {447 -- 452},
year = {1996},
date-added = {2010-10-30 11:59:00 +0100},
date-modified = {2010-10-30 12:01:06 +0100},
doi = {10.1109/CVPR.1996.517110},
pmid = {517110},
URL = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=517110&queryText%253D%2528%2528Interactive+learning+using+a+society+of+models.%2529%2529%2526openedRefinements%253D*%2526sortType%253Ddesc_Publication+Year%2526matchBoolean%253Dtrue%2526rowsPerPage%253D50%2526searchField%253DSearch+All},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Minka,%20Interactive%20learning%20with%20a%20%E2%80%9CSociety%20of%20Models%E2%80%9D.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2247},
rating = {1}
}

@article{Tamura:2002p859,
author = {H Tamura and N Yokoya}, 
journal = {Pattern Recognition},
title = {Image database systems: A survey},
abstract = { 2. WHAT AND WHY?--  2.1.  These categories are due to classifying the   existing around 1977 or found in the literature. Now we should reconsider it, including the state-of-the-art of  technology. },
note = {Extensa lista de image browsers{\ldots}},
year = {2002},
month = {Oct},
date-added = {2010-10-04 12:03:32 +0100},
date-modified = {2010-10-26 11:56:47 +0100},
pmid = {690207212138686413related:zWfwdM0blAkJ},
URL = {http://linkinghub.elsevier.com/retrieve/pii/0031320384900335},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Tamura,%20Image%20database%20systems%20A%20survey.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p859},
read = {Yes},
rating = {1}
}

@article{Cooper:2006p543,
author = {Katy Cooper and Oscar Bruijn and Robert Spence and Mark Witkowski}, 
journal = {AVI '06: Proceedings of the working conference on Advanced visual interfaces},
title = {A comparison of static and moving presentation modes for image collections},
abstract = {In both professional and personal contexts, a common activity is the search for a target image among a collection of images. The presentation of that collection to a user can assume a wide variety of forms, and it would help interaction designers to ...},
annote = {O paper investiga varias formas de apresentar imagens e conclui que visualiza{\c c}{\~o}es est{\'a}ticas s{\~a}o prefer{\'\i}veis {\`a}s animadas pois n{\~a}o s{\'o} {\'e} mais f{\'a}cil a identifica{\c c}{\~a}o de imagens provoca uma melhor experi{\^e}ncia de utiliza{\c c}{\~a}o

Utilizaram t{\'e}cnicas de "eye-tracking" para perceber a reac{\c c}{\~a}o dos utilizadores sujeitos a v{\'a}rios tipos de apresenta{\c c}{\~a}o de imagens. 

O {\^a}mbito deste trabalho {\'e} mais virado para as interfaces e maneiras de mostrar coisa/imagens em ecr{\~a}s. N{\~a}o {\'e} focado na visualisa{\c c}{\~a}o de muitas fotos mas pode ser utilizado refor{\c c}o da ideia de que fotos a mexer n{\~a}o melhora a visualiza{\c c}{\~a}o.},
year = {2006},
month = {May},
keywords = {Resumido, eye-gaze tracking, user preference, rapid serial visual presentation (RSVP)}, 
date-added = {2010-08-09 16:35:33 +0100},
date-modified = {2010-10-28 13:48:37 +0100},
pmid = {1133265.1133345},
URL = {http://portal.acm.org/citation.cfm?id=1133265.1133345},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Cooper,%20A%20comparison%20of%20static%20and%20moving%20presentation%20modes%20for%20image%20collections.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p543},
read = {Yes},
rating = {3}
}

@article{Schaefer:2010p1871,
author = {G Schaefer}, 
journal = {Multimedia Tools and Applications},
title = {A next generation browsing environment for large image repositories},
abstract = {Next generation environments will change the way people work and live as they will provide new advances in areas ranging from remote work and education, e-commerce, gaming to information-on-demand. In many of these applications intel- ligent interpretation of multimedia data such as image, video and audio resources is necessary. In this paper we present an effective approach to handling image repositories providing the user with an intuitive interface of visualising and browsing large collections of pictures. Based on the idea of similarity-based organisation of images where images that are visually similar are located close to each other in visualisation space, images are projected onto a sphere with which the user can interact. Rotating the sphere reveals images of different colours while tilting operations focus on brighter or darker images. Large image collections are handled through a hierarchical approach that brings up similar, previously hidden, images when zooming in on an area. Furthermore, the way images are organised can be interactively changed by the user. Our next generation browsing environment has been successfully tested on a large database of several thousand images.},
year = {2010},
month = {Jan},
date-added = {2010-10-26 10:13:57 +0100},
date-modified = {2010-11-12 15:01:22 +0000},
pmid = {17430722140527232001related:AYSpVG9d5vEJ},
URL = {http://www.springerlink.com/index/E836R60419846G23.pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Schaefer,%20A%20next%20generation%20browsing%20environment%20for%20large%20image%20repositories.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1871},
read = {Yes},
rating = {0}
}

@article{Strong:2009p413,
author = {Grant Strong and Minglun Gong}, 
journal = {CIVR '09: Proceeding of the ACM International Conference on Image and Video Retrieval},
title = {Organizing and browsing photos using different feature vectors and their evaluations},
abstract = {Two-dimensional similarity-based image organizing studies how to place photos within 2D virtual canvas based on their visual contents so that the users can easily locate the desired photos. As an extension to our previous work [10], several improvements are made in this paper to allow better photo browsing experiences. For example, the new approach pre-orders all the photos so that a consistent set of photos is selected for display. This solves the photo flickering problem of our previous approach, which uses K-mean algorithm to dynamically select photos.

The main focus of this paper however is on the evaluation of the effectiveness of different feature vectors for 2D photo organization. A performance metric is proposed to measure how well photos with similar visual contents are grouped together on the 2D canvas. Feature vectors generated using eight different low-level feature extraction approaches are tested. The evaluation results reveal the pros and cons of different feature extraction approaches, which can be a useful guide for developing new feature vectors.},
annote = {Fala muito sobre t{\'e}cnicas para organizar fotos de acordo com as suas cores dizendo que pode ser {\'u}til, porque sim. N{\~a}o tem como interesse estudar se os utilizadores gostam minimamente deste tipo de organiza{\c c}{\~a}o. 

Utilizam um "self organizing map" ou SOM que {\'e} uma esp{\'e}cie de rede neuronal artificial que se sabe organizar. 
O utilizador pode fazer zoom na visualiza{\c c}{\~a}o e s{\~a}o utilizados v{\'a}rios SOMs para as varias resolu{\c c}{\~o}es. 

Utilizam v{\'a}rias formas para determinar a posi{\c c}{\~a}o das imagens no SOM
Histogama de cores, que {\'e} o mais b{\'a}sico. N{\~a}o tem informa{\c c}{\~a}o espacial das cores o que faz com que n{\~a}o seja afectado por rota{\c c}{\~o}es ou escalas mas permite imagens bastante diferentes no seu conte{\'u}do. 
Autocorrela{\c c}{\~a}o de cores calcula a probabilidade de ter cores juntas. Tamb{\'e}m n{\~a}o tem informa{\c c}{\~a}o espacial. 
V{\'a}rios M{\'e}todos com recurso a gradientes. J{\'a} cont{\'e}m informa{\c c}{\~a}o espacial, s{\~a}o sens{\'\i}veis {\`a} rota{\c c}{\~a}o da imagem
Alguns m{\'e}todos h{\'\i}bridos, histograma de cores e grandientes
Todos os 8 m{\'e}todos diferentes s{\~a}o testados e {\'e} mostrado que os h{\'\i}bridos s{\~a}o melhores no geral. 
N{\~a}o fazem qualquer teste com utilizadores em como estes preferem uma visualiza{\c c}{\~a}o baseada em semelhan{\c c}as a outra qualquer.  },
year = {2009},
month = {Jul},
keywords = {Resumido}, 
date-added = {2010-07-21 10:46:29 +0100},
date-modified = {2010-10-26 17:29:31 +0100},
pmid = {1646396.1646401},
URL = {http://portal.acm.org/ft_gateway.cfm?id=1646401&type=pdf&coll=Portal&dl=GUIDE&CFID=97746692&CFTOKEN=35796482},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Strong,%20Organizing%20and%20browsing%20photos%20using%20different%20feature%20vectors%20and%20their%20evaluations.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p413},
read = {Yes},
rating = {4}
}

@article{Qiu:2007p1207,
author = {G Qiu and J Morris and X Fan}, 
journal = {Pattern Recognition},
title = {Visual guided navigation for image retrieval},
abstract = {In this work, we are interested in technologies that will allow users to actively browse and navigate large image databases and to retrieve images through interactive fast browsing and navigation. The development of a browsing/navigation-based image retrieval system has at least two challenges. The first is that the system's graphical user interface (GUI) should intuitively reflect the distribution of the images in the database in order to provide the users with a mental picture of the database content and a sense of orientation during the course of browsing/navigation. The second is that it has to be fast and responsive, and be able to respond to users actions at an interactive speed in order to engage the users. We have developed a method that attempts to address these challenges of a browsing/navigation based image retrieval systems. The unique feature of the method is that we take an integrated approach to the design of the browsing/navigation GUI and the indexing and organization of the images in the database. The GUI is tightly coupled with the algorithms that run in the background. The visual cues of the GUI are logically linked with various parts of the repository (image clusters of various particular visual themes) thus providing intuitive correspondences between the GUI and the database contents. In the backend, the images are organized into a binary tree data structure using a sequential maximal information coding algorithm and each image is indexed by an n-bit binary index thus making response to users' action very fast. We present experimental results to demonstrate the usefulness of our method both as a pre-filtering tool and for developing browsing/navigation systems for fast image retrieval from large image databases.},
annote = {GUI's devem fornecer funcionalidades e indica{\c c}{\~o}es que ajudem o utilizador a navegar pela BD de imagens. Deve reflectir a distribui{\c c}{\~a}o de imagens na BD, criando no utilizador uma imagem mental do seu conte{\'u}do e gerando um sentido de orienta{\c c}{\~a}o no processo de navega{\c c}{\~a}o. E tem que ser r{\'a}pido e responsivo.

Em navegadores de imagens normais, a obtens{\~a}o das imagens {\'e} baseada em compara{\c c}{\~o}es com as outras imagens, calculos de dist{\^a}ncias entre elas, no que {\'e} um processo computacionalmente  pesado.

Os autores tentam explorar como {\'e} que as pessoas organizam um conjunto de imagens e como aplicar isso a software.
O objectivo {\'e} classificar imagens com um identificador simples que descreva uma vaga impress{\~a}o visual. Come{\c c}am com as 11 cores mais comuns. 

Pegam na teoria das cores opostas Vermelho-Verde e Azul-Amarelo e aplicam isso como o mapa de distribui{\c c}{\~a}o das imagens. Determinam a mediana destas cores para cada imagem e colocam-na no grupo respectivo.

Segundo os testes numa BD de 10 000 imagens, foi possivel reduzir o tempo de procura por fotos especificas para cerca de metade. No entanto, como o processo se baseia nas cores da imagem, aquelas que t{\^e}m muitas cores podem ser mais dificeis de encontrar embora, no geral, continue a ser mais r{\'a}pido que navegar por pastas.},
number = {6},
pages = {1711--1721},
volume = {40},
year = {2007},
keywords = {Resumido, Na tese}, 
date-added = {2010-10-04 17:16:53 +0100},
date-modified = {2010-10-26 17:28:25 +0100},
pmid = {559138762201591209related:qW0t5b11wgcJ},
URL = {http://www.sciencedirect.com/science?_ob=ArticleURL&_udi=B6V14-4MG6P34-1&_user=2459750&_coverDate=06%252F30%252F2007&_rdoc=1&_fmt=high&_orig=search&_origin=search&_sort=d&_docanchor=&view=c&_searchStrId=1514737341&_rerunOrigin=scholar.google&_acct=C000057394&_version=1&_urlVersion=0&_userid=2459750&md5=cceabf799ed2598beb7803bb8d0d9fd3&searchtype=a},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Qiu,%20Visual%20guided%20navigation%20for%20image%20retrieval.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p1207},
read = {Yes},
rating = {5}
}

@article{Albuz:1999p284,
author = {Elif Albuz and Erturk Kocalar and Ashfaq A Khokhar}, 
title = {Scalable Color Image Indexing And Retrieval Using Vector Wavelets},
abstract = {This paper presents a scalable content-based image indexing andretrieval system based on vector wavelet coefficients of color images.Highly decorrelated wavelet coefficient planes are used to acquire asearch efficient feature space. The feature space is subsequentlyindexed using properties of all the images in the database. Thereforethe feature key of an image does not only correspond to the contentof the image itself but also how much the image is different from theother images being stored in the database. The search time linearlydepends on the number of images similar to the query image and isindependent of the database size. We show that in a database of 5000images, query search takes less than 30 msec, on a 266 MHz PentiumII processor compared to several seconds of retrieval time in theearlier systems proposed in the literature.Keywords: wavelet transform, content based image indexing, queryby example, image retrieval, scalable indexing and retrieval systems.1. IN...},
affiliation = {University of Delaware; Department of Electrical and Computer Engineering},
year = {1999},
month = {Jul},
language = {eng},
date-added = {2010-07-19 19:33:08 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {357175},
URL = {http://citeseer.ist.psu.edu/357175},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Albuz,%20Scalable%20Color%20Image%20Indexing%20And%20Retrieval%20Using%20Vector%20Wavelets.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p284},
read = {Yes},
rating = {2}
}

@article{Deng:2009p913,
author = {J Deng and W Dong and R Socher and K Li and L Fei-Fei}, 
journal = {computer.org},
title = {Imagenet: A large-scale hierarchical image database},
abstract = {The explosion of  data on the Internet has the po- tential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with im- ages and multimedia data. But exactly how such data can be harnessed and organized remains a critical },
annote = {Objectivo: Atribuir 500-1000 imagens aos conceitos do WordNet, que s{\~a}o {\'a}rvores sem{\^a}nticas{\ldots}
As imagens s{\~a}o obtidas procurando pelas palavras em sites espec{\'\i}ficos, passando depois por uma fase de processamento humano onde, para cada imagem, v{\'a}rias pessoas indicam se o conceito est{\'a} ou n{\~a}o presente e assim s{\~a}o categorizadas as imagens.
},
year = {2009},
month = {Jan},
keywords = {Resumido}, 
date-added = {2010-10-04 12:05:15 +0100},
date-modified = {2010-10-23 21:38:15 +0100},
pmid = {8608616864033186939related:e6QibG3zd3cJ},
URL = {http://www.computer.org/portal/web/csdl/doi/10.1109/CVPRW.2009.5206848},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Deng,%20Imagenet%20A%20large-scale%20hierarchical%20image%20database.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p913},
read = {Yes},
rating = {2}
}

@article{Berman:1999p943,
author = {AP Berman and LG Shapiro}, 
journal = {Computer Vision and Image Understanding},
title = {A Flexible Image Database System for Content-Based Retrieval},
abstract = {There is a growing need for the ability to query  databases based on similarity of content rather than strict keyword search. As distance computations can be expensive, there is a need for indexing systems and algorithms that can eliminate candidate },
year = {1999},
month = {Jan},
date-added = {2010-10-04 12:04:13 +0100},
date-modified = {2010-11-05 12:03:43 +0000},
pmid = {12684872023498274381related:Tbbn5eW3CbAJ},
URL = {http://linkinghub.elsevier.com/retrieve/pii/S1077314299907725},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Berman,%20A%20Flexible%20Image%20Database%20System%20for%20Content-Based%20Retrieval.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p943},
read = {Yes},
rating = {0}
}

@article{Strong:2008p414,
author = {Grant Strong and Minglun Gong}, 
journal = {ISVC '08: Proceedings of the 4th International Symposium on Advances in Visual Computing, Part II},
title = {Browsing a Large Collection of Community Photos Based on Similarity on GPU},
abstract = {A novel approach is proposed in this paper to facilitate browsing a large collection of community photos based on visual similarities. Using extracted feature vectors, the approach maps photos onto a 2D rectangular area such that the ones with similar features are close to each other. When a user browses the collection, a subset of photos is automatically selected to compose a photo collage. Once having identified photos of interest the user can find more photos with similar features through panning and zooming operations, which dynamically update the photo collage. To quickly organize a large number of photos, the 2D mapping process is performed on the GPU, which yields 15~19 times speedup over the CPU implementation.},
annote = {Pode ser importante embora seja baseado em compara{\c c}{\~o}es no GPU{\ldots}},
year = {2008},
month = {Dec},
date-added = {2010-07-21 10:46:29 +0100},
date-modified = {2010-10-26 11:52:41 +0100},
pmid = {1486099.1486143},
URL = {http://portal.acm.org/citation.cfm?id=1486099.1486143},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p414},
rating = {3}
}

@article{Chen:2002p2469,
author = {Jau-Yuen Chen and Charles A Bouman}, 
journal = {Image Processing},
title = {Hierarchical browsing and search of large image databases},
abstract = {Abstract---The advent of  (>10000) has created a need for tools which can  and organize  automatically by their content. This paper focuses on the use of  tree-structures to both speed-up -by-query and organize },
year = {2002},
month = {Jan},
date-added = {2010-10-30 16:49:52 +0100},
date-modified = {2010-11-10 16:56:05 +0000},
pmid = {12065845356883266136related:WMrSq2x-cqcJ},
URL = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=826781},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Chen,%20Hierarchical%20browsing%20and%20search%20of%20large%20image%20databases.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2469},
read = {Yes},
rating = {0}
}

@article{Krishnamachari:1999p682,
author = {S Krishnamachari and M Abdel-Mottaleb}, 
journal = {Computers and Communications, 1999. Proceedings. IEEE International Symposium on},
title = {Image browsing using hierarchical clustering},
abstract = {Digital images and video clips are becoming popular due to the increase in the availability of consumer devices that capture digital images and video clips. Digital content is also growing over the Internet. The increase of the digital content creates a need for user-friendly tools to browse through large volumes of digital material. We present a clustering-based browsing algorithm. Images are automatically clustered using a hierarchical clustering algorithm and users can then browse through the images by navigating the tree structure that results from the clustering. We have tested the algorithm on a large number of images},
pages = {301 -- 307},
year = {1999},
date-added = {2010-08-09 16:48:28 +0100},
date-modified = {2010-11-11 20:00:07 +0000},
doi = {10.1109/ISCC.1999.780837},
pmid = {780837},
URL = {http://ieeexplore.ieee.org/search/srchabstract.jsp?tp=&arnumber=780837&queryText%253D%2528%2528Document+Title%253AImage+Browsing+Using+Hierarchical+Clustering%2529%2529%2526openedRefinements%253D*%2526sortType%253Ddesc_Publication+Year%2526matchBoolean%253Dtrue%2526rowsPerPage%253D50%2526searchField%253DSearch+All},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Krishnamachari,%20Image%20browsing%20using%20hierarchical%20clustering.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p682},
read = {Yes},
rating = {1}
}

@article{Minka:1996p918,
author = {T Minka and R Picard}, 
journal = {Master's thesis},
title = {An image database browser that learns from user interaction},
abstract = {Digital libraries of  and video are rapidly growing in size and availability. To avoid the expense and limitations of text, there is considerable interest in navigation by perceptual and other automatically extractable attributes. Unfortunately, the relevance of an attribute for a },
year = {1996},
month = {Jan},
date-added = {2010-10-04 12:04:26 +0100},
date-modified = {2010-10-23 21:35:40 +0100},
pmid = {8543538155611113666related:wkgy2q--kHYJ},
URL = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.38.7765&rep=rep1&type=pdf},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Minka,%20An%20image%20database%20browser%20that%20learns%20from%20user%20interaction.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p918},
read = {Yes},
rating = {0}
}

@article{Hsu:2009p2696,
author = {SH Hsu and P Cubaud and S Jumpertz}, 
journal = {Human-Computer Interaction. Novel Interaction Methods and Techniques},
title = {Phorigami: A Photo browser based on meta-categorization and origami visualization},
abstract = {Phorigami is a photo browser whose meta-interface visualizes photos by groups according to the analysis of photo contexts. At the core of Phorigami, we proposed a meta-categorization for photo regrouping. This categorization method encompasses the scope of current or expected recognition technologies. Two experiments are conducted by manual classification tasks to study the pertinence of proposed categorization method. We then outline our meta- interface by applying different interaction technique to feature each photo group.},
annote = {This paper tries to ease the browsing problem by analysing the collections and identifying groups of related pictures. Each type of group is visualised in a specific way, inspired by the Origami art.

Groups of similar or related photos were manually classified based on camera movement and subject movement, creating different types of groups static view where both camera and subject are fixed and is presented as a panorama; multi-view where the subject is fixed but the camera is moving and is shown as a presentation; if the subject is moving, the photos are categorised as motion capture and can be shown as an animated photo (fixed camera) or a presentation (moving camera); finally group photos, where different groups of people are photographed, are shown as a folding presentation.

This covers various cases where the photographer takes a few similar photos of the same subject because it's either a panorama, various angles or just to be sure the photo it has a well captured photo. 

The interface implements the different presentation types as different metaphors, easy for the user to understand, like a folded paper on a wide panorama that can be expanded. Although some of them appear to be a little hard to distinguish in its compressed form, it shouldn't be hard to make it clearer. Other possible problem is the use of different touch interactions for each presentation type that might confuse users on what gesture should they use.},
pages = {801--810},
year = {2009},
date-added = {2010-11-08 16:45:38 +0000},
date-modified = {2011-01-20 18:30:20 +0000},
pmid = {12203599880520366985related:iXtqE2_lW6kJ},
URL = {http://www.google.com/search?client=safari&rls=en-us&q=Phorigami:+A+Photo+browser+based+on+meta-categorization+and+origami+visualization&ie=UTF-8&oe=UTF-8},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Hsu,%20Phorigami%20A%20Photo%20browser%20based%20on%20meta-categorization%20and%20origami%20visualization.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2696},
read = {Yes},
rating = {0}
}

@article{Platt:2004p2831,
author = {J Platt and M Czerwinski{\ldots}}, 
journal = {{\ldots} Communications and Signal {\ldots}},
title = {Phototoc: Automatic clustering for browsing personal photographs},
abstract = {Taking  with a digital camera is so convenient and low cost that it is easy for a user to generate more than  1.1 Related Work There have heen several image browsers proposed in the liter- ature. In Similarity Pyramids [21 and the work of [12], pho- tographs are },
year = {2004},
month = {Jan},
date-added = {2010-11-10 15:35:34 +0000},
date-modified = {2010-11-10 15:35:34 +0000},
pmid = {9750847248541327803related:u6FmDOn3UYcJ},
URL = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1292402},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Platt,%20Phototoc%20Automatic%20clustering%20for%20browsing%20personal%20photographs.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2831},
read = {Yes},
rating = {0}
}

@article{Christmann:2006p2833,
author = {O Christmann and N Carbonell}, 
journal = {Proceedings of the working conference on Advanced visual interfaces},
title = {Browsing through 3D representations of unstructured picture collections: an empirical study},
abstract = {The paper presents a 3D interactive representation of fairly large picture	collections	which	facilitates	browsing	through unstructured sets of icons or pictures. Implementation of this representation implies choosing between two visualization strategies: users may either manipulate the view (OV) or be immersed in it (IV). The paper first presents this representation, then describes an empirical study (17 participants) aimed at assessing the utility and usability of each view. Subjective judgements in questionnaires and debriefings were varied: 7 participants preferred the IV view, 4 the OV one, and 6 could not choose between the two. Visual acuity and visual exploration strategies seem to have exerted a greater influence on participants' preferences than task performance or feeling of immersion.},
pages = {445--448},
year = {2006},
keywords = {N{\~a}o compara com o 2D}, 
date-added = {2010-11-11 17:40:30 +0000},
date-modified = {2010-11-11 18:55:56 +0000},
pmid = {10637356298592132478related:fh3ZxjF7n5MJ},
local-url = {file://localhost/Users/carlos/Dropbox/Tese/Papers/Christmann,%20Browsing%20through%203D%20representations%20of%20unstructured%20picture%20collections%20an%20empirical%20study.pdf},
uri = {papers://45421056-10A4-40D0-94FC-434C320F5EA4/Paper/p2833},
read = {Yes},
rating = {1}
}

